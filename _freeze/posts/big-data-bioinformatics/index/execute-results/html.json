{
  "hash": "1edb5ca0c752d219d3c1f107f4de5f10",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'How to operate large files in bioinformatics'\nauthor: 'Flávia E. Rius'\ndate: '2025-02-11'\ncategories: [bioinformatics, cloud computing]\nwebsite:\n    google-analytics: 'G-S78JRQSZER'\n---\n\n\n\nSituation: you start all happy that you will be analyzing your sequencing data, be it transcriptomic, genomic or epigenomic; you have learned bash, R and statistics, and then you try to transfer all of the data to your computer, and then you see that, bleh, you don't have enough storage in your computer. Then what?\n\nYou start panicking? No!\n\nYou start searching the web about that, and come up with a gazillion new terms that you have never heard of. _Server_, _cluster_, _cloud computing_, _ssh_, _ssd_, _bucket_, to enumerate a few. And now you panic for real.\n\n![](DALL·E 2025-02-18 21.49.29 - A beginner programmer sitting nervously in front of a large computer screen filled with complex lines of code. The person, wearing casual clothes, has.webp){fig-alt=\"A beginner bioinformatician worried about operating large files\" fig-align=\"center\" width=50%}.\n\nDon't worry, I am here to help! I'll get straight to the point about the options available to tackle this problem when working with big data in bioinformatics.\n\nBasically you have two main options:\n\n- Cloud computing\n\n- Server/cluster of your institution (when available)\n\n## Cloud computing\n\n\nThese are the services provided by companies where you can pay for a temporary remote machine to run your analyses. Google Cloud, aws and Azure are the most well-known providers of this type of service. Basically you need to create an account, link to a payment method, and start using it.\n\nIf this is your option, you need to learn the basics on how to analyze data in the cloud. I would go with the simplest way which is creating an instance. An instance is nothing more than a computer you configure remotely. You need to pick a size of CPU, RAM memory and storage, which can be HDD (popularly known as HD, cheaper and slower) or SSD (faster to transfer data, but more expensive). Then, you just transfer your data to the instance using wget or ssh, depending on where this data will come from, and you can work from there (using the command line, of course).\n\n### Google Cloud Compute Engine\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#TODO insert image of google cloud instances\n```\n:::\n\n\n\nBelow I will give you some details on how to do this on Google Cloud Compute Engine.\nThey give $300 of free credits to new Google Cloud users, so you can test and potentially do the analysis you need for free. To give you an idea of costs, a general use machine with 4 CPUs, 15GB of memory (RAM) and 100GB of HDD storage, and running for 30 days [would cost you 140 USD](https://cloud.google.com/products/calculator?dl=CiRjMzE2MjBkMC0yZjk0LTQ2MTItYjk5Mi0zODU3Y2NkMjAyMDkQCBokMkM4Qjg5MzUtMzMyMy00MTgyLTg3QkYtQTQ2RDRDRkE3MDM1). You can calculate the expected amount for your personalized needs in the calculator page.\n\nAfter setting up your instance and transferring the data, you need to install all software needed to run your analyses from scratch. For example, let's say that you want to run an RNA-seq alignment using STAR. You will need to install STAR, transfer the reference genome or transcriptome to the instance, build the reference for this program, and then run it. Don't forget that any other tools you might need for previous steps such as QC must be installed to the instance too. After all, it is a new computer you are renting for a limited time.\n\nAfter finishing your analysis, you need to deal with the generated data. Let's talk about this in another post, because it is a topic that deserves better attention.\n\n\n## Server/cluster in your university\n![Photo by <a href=\"https://unsplash.com/@tvick?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Taylor Vick</a> on <a href=\"https://unsplash.com/photos/cable-network-M5tzZtFCOfs?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a>](server-unsplash.jpg)\n      \n\nIn this option there are two different ways that a server might be provided to you: via a job schedule strategy or by giving you access to a slice of this server.\n\nA server, as the instance in the cloud computing resource, is a remote computer to which you have access. The job schedule strategy requires you to learn how to structure your data and then you need to write your scripts and submit them to the job scheduler, then wait for your turn to run them, as other people send their jobs to the scheduler too. The most popular examples are Slurm and SGE.\n\nGenerally there is a free limited space (scratch) of the server for you to experiment with a slice of the data (so you are certain that your script is correct to send to schedule for example). Some more complex labs allow you to send to a specific server schedule line, depending on your demand of cpu and processing. These are aspects you may require by task as well when submitting your job to the line schedule.\n\nAnother way of doing this, generally in less experienced labs, is by requiring a specific slice of the server available in the university for you to use during your full project. In my PhD I knew that I could have asked for it in my university, but I did not have a bit of idea on what would be my CPU, RAM memory and storage needs. Therefore I could not get it. I still relied on my collaborator server to finish my analyses. So this is an important knowledge to have.\n\nAs important as it might sound, how to calculate the machine needed for your bioinformatics analyses will need to be addressed in a new blog post. It depends on too many factors.\n\nI hope this post has helped you in your bioinformatics journey!\n\nDid I miss any points? Let me know in the comments below if you have something to add to this post!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}